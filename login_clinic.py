import os

target_file = "backend/streamlit_app.py"

# ë°©ë¬¸ í›„ ë¡œê·¸ì¸(Visit-First) ë¡œì§ + ìƒì„¸ ì—ëŸ¬ ë¦¬í¬íŒ…
clinic_code = """import streamlit as st
import requests
import pandas as pd
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import urllib3

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

class EbcCrawler:
    def __init__(self):
        self.session = requests.Session()
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Linux; Android 10; K) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Mobile Safari/537.36',
            'Referer': 'https://m.ebcblue.com/',
            'Origin': 'https://m.ebcblue.com'
        }
        self.login_url = "https://m.ebcblue.com/bbs/login_check.php"

    def login(self, user_id, user_pw):
        try:
            # [1ë‹¨ê³„] ë©”ì¸ í˜ì´ì§€ ë¨¼ì € ë°©ë¬¸ (ì¿ í‚¤/ì„¸ì…˜ íšë“ - ì¤‘ìš”!)
            self.session.get('https://m.ebcblue.com/', headers=self.headers, verify=False)
            
            # [2ë‹¨ê³„] ë¡œê·¸ì¸ ì‹œë„
            data = {'mb_id': user_id, 'mb_password': user_pw, 'url': 'https://m.ebcblue.com/'}
            res = self.session.post(self.login_url, data=data, headers=self.headers, verify=False)
            res.encoding = res.apparent_encoding # í•œê¸€ ê¹¨ì§ ë°©ì§€

            # [3ë‹¨ê³„] ì„œë²„ ì‘ë‹µ ë¶„ì„ (ì™œ ì‹¤íŒ¨í–ˆëŠ”ì§€ í™•ì¸)
            if 'ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë¦½ë‹ˆë‹¤' in res.text:
                return False, "âŒ ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë ¸ë‹¤ê³  í•©ë‹ˆë‹¤."
            if 'ì¡´ì¬í•˜ì§€ ì•ŠëŠ”' in res.text or 'ì•„ì´ë””ê°€ ì—†ê±°ë‚˜' in res.text:
                return False, "âŒ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì•„ì´ë””ë¼ê³  í•©ë‹ˆë‹¤."
            if 'ì°¨ë‹¨' in res.text:
                return False, "âŒ ì ‘ì†ì´ ì°¨ë‹¨ëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤."

            # [4ë‹¨ê³„] ì§„ì§œ ë¡œê·¸ì¸ ëëŠ”ì§€ ì¬í™•ì¸
            main_res = self.session.get('https://m.ebcblue.com/', headers=self.headers, verify=False)
            if 'ë¡œê·¸ì•„ì›ƒ' in main_res.text or 'logout' in main_res.text:
                return True, "âœ… ë¡œê·¸ì¸ ì„±ê³µ!"
            else:
                # ë¡œê·¸ì¸ ì„±ê³µ ë©”ì‹œì§€ë„ ì—†ê³ , ì—ëŸ¬ë„ ì—†ëŠ”ë° ë¡œê·¸ì¸ì´ ì•ˆ ëœ ê²½ìš°
                return False, "âš ï¸ ì„œë²„ê°€ ë¡œê·¸ì¸ì„ ë¬´ì‹œí–ˆìŠµë‹ˆë‹¤. (ì•Œ ìˆ˜ ì—†ëŠ” ì´ìœ )"
                
        except Exception as e:
            return False, f"ì—ëŸ¬ ë°œìƒ: {str(e)}"

    def scan_links(self, url, keyword):
        st.info("ğŸ” í˜ì´ì§€ ìŠ¤ìº” ì¤‘...")
        found_data = []
        try:
            res = self.session.get(url, headers=self.headers, verify=False)
            res.encoding = res.apparent_encoding
            soup = BeautifulSoup(res.text, 'html.parser')

            if keyword and keyword not in res.text:
                st.error(f"âŒ '{keyword}' ë‹¨ì–´ ì—†ìŒ.")
                return []

            for a in soup.find_all('a', href=True):
                text = a.get_text(strip=True)
                href = a['href']
                full_link = urljoin(url, href)

                if not keyword or (keyword and keyword in text):
                    if len(text) > 0 and 'javascript' not in href:
                        found_data.append({"ì œëª©": text, "ë§í¬": full_link})
            return found_data
        except: return []

# UI êµ¬ì„±
st.set_page_config(page_title="MOIM ë¡œê·¸ì¸ í´ë¦¬ë‹‰", layout="wide")
st.title("ğŸ©º MOIM ë²ˆì—­ê¸° : ë¡œê·¸ì¸ ì •ë°€ ì§„ë‹¨")

with st.sidebar:
    st.header("ë¡œê·¸ì¸")
    user_id = st.text_input("ì•„ì´ë””", key="uid")
    user_pw = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="upw")

st.subheader("1. ê²€ìƒ‰ ì„¤ì •")
url = st.text_input("íƒ€ê²Ÿ URL", "http://m.ebcblue.com/")
keyword = st.text_input("ì°¾ì„ í‚¤ì›Œë“œ", placeholder="ë¹„ì›Œë‘ë©´ ì „ì²´ ê²€ìƒ‰")

if st.button("ğŸš€ ë¡œê·¸ì¸í•˜ê³  ì›ì¸ ë¶„ì„í•˜ê¸°"):
    if not user_id or not user_pw:
        st.error("ì•„ì´ë””ì™€ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        crawler = EbcCrawler()
        status = st.empty()
        status.info("ğŸ”‘ ë¡œê·¸ì¸ ì‹œë„ ì¤‘ (ë°©ë¬¸ -> ë¡œê·¸ì¸)...")
        
        # ìƒì„¸ ê²°ê³¼ ë°›ê¸°
        is_success, message = crawler.login(user_id, user_pw)
        
        if is_success:
            status.success(message)
            results = crawler.scan_links(url, keyword)
            if results:
                st.success(f"ğŸ‰ {len(results)}ê°œì˜ ê²°ê³¼ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                
                # ì•ˆì „í•œ í…Œì´ë¸” ì¶œë ¥
                table_head = "| ì œëª© | ë°”ë¡œê°€ê¸° |\\n"
                table_div = "|---|---|\\n"
                md_table = table_head + table_div
                for row in results:
                    row_str = f"| {row['ì œëª©']} | [ì´ë™í•˜ê¸°]({row['ë§í¬']}) |\\n"
                    md_table += row_str
                st.markdown(md_table)
            else:
                st.warning("ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            status.error(message) # ì„œë²„ê°€ ì•Œë ¤ì¤€ ì§„ì§œ ê±°ì ˆ ì‚¬ìœ  ì¶œë ¥
"""import os

target_file = "backend/streamlit_app.py"

# ë°©ë¬¸ í›„ ë¡œê·¸ì¸(Visit-First) ë¡œì§ + ìƒì„¸ ì—ëŸ¬ ë¦¬í¬íŒ…
clinic_code = """import streamlit as st
import requests
import pandas as pd
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import urllib3

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

class EbcCrawler:
    def __init__(self):
        self.session = requests.Session()
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Linux; Android 10; K) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Mobile Safari/537.36',
            'Referer': 'https://m.ebcblue.com/',
            'Origin': 'https://m.ebcblue.com'
        }
        self.login_url = "https://m.ebcblue.com/bbs/login_check.php"

    def login(self, user_id, user_pw):
        try:
            # [1ë‹¨ê³„] ë©”ì¸ í˜ì´ì§€ ë¨¼ì € ë°©ë¬¸ (ì¿ í‚¤/ì„¸ì…˜ íšë“ - ì¤‘ìš”!)
            self.session.get('https://m.ebcblue.com/', headers=self.headers, verify=False)
            
            # [2ë‹¨ê³„] ë¡œê·¸ì¸ ì‹œë„
            data = {'mb_id': user_id, 'mb_password': user_pw, 'url': 'https://m.ebcblue.com/'}
            res = self.session.post(self.login_url, data=data, headers=self.headers, verify=False)
            res.encoding = res.apparent_encoding # í•œê¸€ ê¹¨ì§ ë°©ì§€

            # [3ë‹¨ê³„] ì„œë²„ ì‘ë‹µ ë¶„ì„ (ì™œ ì‹¤íŒ¨í–ˆëŠ”ì§€ í™•ì¸)
            if 'ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë¦½ë‹ˆë‹¤' in res.text:
                return False, "âŒ ë¹„ë°€ë²ˆí˜¸ê°€ í‹€ë ¸ë‹¤ê³  í•©ë‹ˆë‹¤."
            if 'ì¡´ì¬í•˜ì§€ ì•ŠëŠ”' in res.text or 'ì•„ì´ë””ê°€ ì—†ê±°ë‚˜' in res.text:
                return False, "âŒ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì•„ì´ë””ë¼ê³  í•©ë‹ˆë‹¤."
            if 'ì°¨ë‹¨' in res.text:
                return False, "âŒ ì ‘ì†ì´ ì°¨ë‹¨ëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤."

            # [4ë‹¨ê³„] ì§„ì§œ ë¡œê·¸ì¸ ëëŠ”ì§€ ì¬í™•ì¸
            main_res = self.session.get('https://m.ebcblue.com/', headers=self.headers, verify=False)
            if 'ë¡œê·¸ì•„ì›ƒ' in main_res.text or 'logout' in main_res.text:
                return True, "âœ… ë¡œê·¸ì¸ ì„±ê³µ!"
            else:
                # ë¡œê·¸ì¸ ì„±ê³µ ë©”ì‹œì§€ë„ ì—†ê³ , ì—ëŸ¬ë„ ì—†ëŠ”ë° ë¡œê·¸ì¸ì´ ì•ˆ ëœ ê²½ìš°
                return False, "âš ï¸ ì„œë²„ê°€ ë¡œê·¸ì¸ì„ ë¬´ì‹œí–ˆìŠµë‹ˆë‹¤. (ì•Œ ìˆ˜ ì—†ëŠ” ì´ìœ )"
                
        except Exception as e:
            return False, f"ì—ëŸ¬ ë°œìƒ: {str(e)}"

    def scan_links(self, url, keyword):
        st.info("ğŸ” í˜ì´ì§€ ìŠ¤ìº” ì¤‘...")
        found_data = []
        try:
            res = self.session.get(url, headers=self.headers, verify=False)
            res.encoding = res.apparent_encoding
            soup = BeautifulSoup(res.text, 'html.parser')

            if keyword and keyword not in res.text:
                st.error(f"âŒ '{keyword}' ë‹¨ì–´ ì—†ìŒ.")
                return []

            for a in soup.find_all('a', href=True):
                text = a.get_text(strip=True)
                href = a['href']
                full_link = urljoin(url, href)

                if not keyword or (keyword and keyword in text):
                    if len(text) > 0 and 'javascript' not in href:
                        found_data.append({"ì œëª©": text, "ë§í¬": full_link})
            return found_data
        except: return []

# UI êµ¬ì„±
st.set_page_config(page_title="MOIM ë¡œê·¸ì¸ í´ë¦¬ë‹‰", layout="wide")
st.title("ğŸ©º MOIM ë²ˆì—­ê¸° : ë¡œê·¸ì¸ ì •ë°€ ì§„ë‹¨")

with st.sidebar:
    st.header("ë¡œê·¸ì¸")
    user_id = st.text_input("ì•„ì´ë””", key="uid")
    user_pw = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password", key="upw")

st.subheader("1. ê²€ìƒ‰ ì„¤ì •")
url = st.text_input("íƒ€ê²Ÿ URL", "http://m.ebcblue.com/")
keyword = st.text_input("ì°¾ì„ í‚¤ì›Œë“œ", placeholder="ë¹„ì›Œë‘ë©´ ì „ì²´ ê²€ìƒ‰")

if st.button("ğŸš€ ë¡œê·¸ì¸í•˜ê³  ì›ì¸ ë¶„ì„í•˜ê¸°"):
    if not user_id or not user_pw:
        st.error("ì•„ì´ë””ì™€ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        crawler = EbcCrawler()
        status = st.empty()
        status.info("ğŸ”‘ ë¡œê·¸ì¸ ì‹œë„ ì¤‘ (ë°©ë¬¸ -> ë¡œê·¸ì¸)...")
        
        # ìƒì„¸ ê²°ê³¼ ë°›ê¸°
        is_success, message = crawler.login(user_id, user_pw)
        
        if is_success:
            status.success(message)
            results = crawler.scan_links(url, keyword)
            if results:
                st.success(f"ğŸ‰ {len(results)}ê°œì˜ ê²°ê³¼ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                
                # ì•ˆì „í•œ í…Œì´ë¸” ì¶œë ¥
                table_head = "| ì œëª© | ë°”ë¡œê°€ê¸° |\\n"
                table_div = "|---|---|\\n"
                md_table = table_head + table_div
                for row in results:
                    row_str = f"| {row['ì œëª©']} | [ì´ë™í•˜ê¸°]({row['ë§í¬']}) |\\n"
                    md_table += row_str
                st.markdown(md_table)
            else:
                st.warning("ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            status.error(message) # ì„œë²„ê°€ ì•Œë ¤ì¤€ ì§„ì§œ ê±°ì ˆ ì‚¬ìœ  ì¶œë ¥
"""

with open(target_file, "w", encoding="utf-8") as f:
    f.write(clinic_code)

print("âœ… [í´ë¦¬ë‹‰ íŒ¨ì¹˜ ì™„ë£Œ] ì´ì œ ì„œë²„ì˜ ê±°ì ˆ ì‚¬ìœ ë¥¼ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
